
@book{phd_statquest_2022,
	title = {The {StatQuest} {Illustrated} {Guide} {To} {Machine} {Learning}},
	isbn = {9798811583607},
	abstract = {Machine Learning is awesome and powerful, but it can also appear incredibly complicated. That’s where The StatQuest Illustrated Guide to Machine Learning comes in. This book takes the machine learning algorithms, no matter how complicated, and breaks them down into small, bite-sized pieces that are easy to understand. Each concept is clearly illustrated to provide you, the reader, with an intuition about how the methods work that goes beyond the equations alone. The StatQuest Illustrated Guide does not dumb down the concepts. Instead, it builds you up so that you are smarter and have a deeper understanding of Machine Learning.The StatQuest Illustrated Guide to Machine Learning starts with the basics, showing you what machine learning is and what are its goals, and builds on those, one picture at a time, until you have mastered the concepts behind self driving cars and facial recognition.},
	language = {English},
	publisher = {Independently published},
	author = {PhD, Josh Starmer},
	month = may,
	year = {2022},
}

@book{james_introduction_2013,
	address = {New York},
	edition = {1st ed. 2013, Corr. 7th printing 2017 edition},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R}},
	isbn = {978-1-4614-7137-0},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
	language = {English},
	publisher = {Springer},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	month = jun,
	year = {2013},
}

@article{rajula_comparison_2020,
	title = {Comparison of {Conventional} {Statistical} {Methods} with {Machine} {Learning} in {Medicine}: {Diagnosis}, {Drug} {Development}, and {Treatment}},
	volume = {56},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1648-9144},
	shorttitle = {Comparison of {Conventional} {Statistical} {Methods} with {Machine} {Learning} in {Medicine}},
	url = {https://www.mdpi.com/1648-9144/56/9/455},
	doi = {10.3390/medicina56090455},
	abstract = {Futurists have anticipated that novel autonomous technologies, embedded with machine learning (ML), will substantially influence healthcare. ML is focused on making predictions as accurate as possible, while traditional statistical models are aimed at inferring relationships between variables. The benefits of ML comprise flexibility and scalability compared with conventional statistical approaches, which makes it deployable for several tasks, such as diagnosis and classification, and survival predictions. However, much of ML-based analysis remains scattered, lacking a cohesive structure. There is a need to evaluate and compare the performance of well-developed conventional statistical methods and ML on patient outcomes, such as survival, response to treatment, and patient-reported outcomes (PROs). In this article, we compare the usefulness and limitations of traditional statistical methods and ML, when applied to the medical field. Traditional statistical methods seem to be more useful when the number of cases largely exceeds the number of variables under study and a priori knowledge on the topic under study is substantial such as in public health. ML could be more suited in highly innovative fields with a huge bulk of data, such as omics, radiodiagnostics, drug development, and personalized treatment. Integration of the two approaches should be preferred over a unidirectional choice of either approach.},
	language = {en},
	number = {9},
	urldate = {2024-09-18},
	journal = {Medicina},
	author = {Rajula, Hema Sekhar Reddy and Verlato, Giuseppe and Manchia, Mirko and Antonucci, Nadia and Fanos, Vassilios},
	month = sep,
	year = {2020},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {autonomous technology, diagnosis, drug development, healthcare, machine learning, medicine, personalized treatment},
	pages = {455},
	file = {Full Text PDF:C\:\\Users\\lmwol\\Zotero\\storage\\UA2DUUNR\\Rajula et al. - 2020 - Comparison of Conventional Statistical Methods wit.pdf:application/pdf},
}

@article{grant_machine_2022,
	title = {Machine learning versus traditional methods for the development of risk stratification scores: a case study using original {Canadian} {Syncope} {Risk} {Score} data},
	volume = {17},
	issn = {1970-9366},
	shorttitle = {Machine learning versus traditional methods for the development of risk stratification scores},
	url = {https://doi.org/10.1007/s11739-021-02873-y},
	doi = {10.1007/s11739-021-02873-y},
	abstract = {Artificial Intelligence and machine learning (ML) methods are promising for risk-stratification, but the added benefit over traditional statistical methods remains unclear. We compared predictive models developed using machine learning (ML) methods to the Canadian Syncope Risk Score (CSRS), a risk-tool developed with logistic regression for predicting serious adverse events (SAE) after emergency department (ED) disposition for syncope. We used the prospective multicenter cohort data collected for CSRS development at 11 Canadian EDs over an 8-year period to develop four ML models to predict 30-day SAE (death, arrhythmias, MI, structural heart disease, pulmonary embolism, hemorrhage) after ED disposition. The CSRS derivation and validation cohorts were used for training and testing, respectively, and the 43 variables used included demographics, medical history, vital signs, ECG findings, blood tests and the diagnostic impression of the emergency physician. Performance was assessed using the area under the receiver-operating-characteristics curve (AUC) and calibration curves. Of the 4030 patients in the training set and 3819 patients in the test set overall, 286 (3.6\%) patients suffered 30-day SAE. The AUCs for model validation in test data were CSRS 0.902 (0.877–0.926), regularized regression 0.903 (0.877–0.928), gradient boosting 0.914 (0.894–0.934), deep neural network 0.906 (0.883–0.929), simplified gradient boosting 0.904 (0.881–0.927). The AUCs and calibration slopes for the ML models and CSRS were similar. Two ML models used fewer predictors than the CSRS but matched its performance. Overall, the ML models matched the CSRS in performance, with some models using fewer predictors.},
	language = {en},
	number = {4},
	urldate = {2024-09-18},
	journal = {Internal and Emergency Medicine},
	author = {Grant, Lars and Joo, Pil and Nemnom, Marie-Joe and Thiruganasambandamoorthy, Venkatesh},
	month = jun,
	year = {2022},
	keywords = {Prediction, Artificial intelligence, Artificial Intelligence, Machine learning, Medical Imaging, Risk stratification, Syncope},
	pages = {1145--1153},
	file = {Full Text PDF:C\:\\Users\\lmwol\\Zotero\\storage\\FXXMS4HB\\Grant et al. - 2022 - Machine learning versus traditional methods for th.pdf:application/pdf},
}

@article{medeiros_forecasting_2021,
	title = {Forecasting {Inflation} in a {Data}-{Rich} {Environment}: {The} {Benefits} of {Machine} {Learning} {Methods}},
	volume = {39},
	issn = {0735-0015},
	shorttitle = {Forecasting {Inflation} in a {Data}-{Rich} {Environment}},
	url = {https://doi.org/10.1080/07350015.2019.1637745},
	doi = {10.1080/07350015.2019.1637745},
	abstract = {Inflation forecasting is an important but difficult task. Here, we explore advances in machine learning (ML) methods and the availability of new datasets to forecast U.S. inflation. Despite the skepticism in the previous literature, we show that ML models with a large number of covariates are systematically more accurate than the benchmarks. The ML method that deserves more attention is the random forest model, which dominates all other models. Its good performance is due not only to its specific method of variable selection but also the potential nonlinearities between past key macroeconomic variables and inflation. Supplementary materials for this article are available online.},
	number = {1},
	urldate = {2024-10-02},
	journal = {Journal of Business \& Economic Statistics},
	author = {Medeiros, Marcelo C. and Vasconcelos, Gabriel F. R. and Veiga, Álvaro and Zilberman, Eduardo},
	month = jan,
	year = {2021},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/07350015.2019.1637745},
	keywords = {Machine learning, Big data, Inflation forecasting, LASSO, Random forests},
	pages = {98--119},
	file = {Full Text PDF:C\:\\Users\\lmwol\\Zotero\\storage\\ZFPRHX6Y\\Medeiros et al. - 2021 - Forecasting Inflation in a Data-Rich Environment .pdf:application/pdf},
}

@article{wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	copyright = {Copyright (c) 2013 Hadley  Wickham},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v059.i10},
	doi = {10.18637/jss.v059.i10},
	abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
	language = {en},
	urldate = {2024-10-02},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	month = sep,
	year = {2014},
	pages = {1--23},
}

@book{grolemund_welcome_nodate,
	title = {Welcome {\textbar} {R} for {Data} {Science}},
	url = {https://r4ds.had.co.nz/},
	abstract = {This book will teach you how to do data science with R: You’ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you’ll learn how to clean data and draw plots—and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You’ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You’ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data.},
	language = {en},
	urldate = {2024-10-02},
	author = {Grolemund, Hadley Wickham {and} Garrett},
}

@book{grolemund_r_2017,
	address = {Beijing Boston Farnham Sebastopol Tokyo},
	edition = {1st edition},
	title = {R for {Data} {Science}: {Import}, {Tidy}, {Transform}, {Visualize}, and {Model} {Data}},
	isbn = {978-1-4919-1039-9},
	shorttitle = {R for {Data} {Science}},
	abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible.  Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You'll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you've learned along the way.  You'll learn how to: Wrangleâ??transform your datasets into a form convenient for analysis Programâ??learn powerful R tools for solving data problems with greater clarity and ease Exploreâ??examine your data, generate hypotheses, and quickly test them Modelâ??provide a low-dimensional summary that captures true "signals" in your dataset Communicateâ??learn R Markdown for integrating prose, code, and results},
	language = {English},
	publisher = {O'Reilly Media},
	author = {Grolemund, Garrett and Wickham, Hadley},
	month = jan,
	year = {2017},
}

@book{rhys_machine_2020,
	address = {Shelter Island, NY},
	edition = {1st edition},
	title = {Machine {Learning} with {R}, the tidyverse, and mlr},
	isbn = {978-1-61729-657-4},
	abstract = {Summary Machine learning (ML) is a collection of programming techniques for discovering relationships in data. With ML algorithms, you can cluster and classify data for tasks like making recommendations or fraud detection and make predictions for sales trends, risk analysis, and other forecasts. Once the domain of academic data scientists, machine learning has become a mainstream business process, and tools like the easy-to-learn R programming language put high-quality data analysis in the hands of any programmer. Machine Learning with R, the tidyverse, and mlr teaches you widely used ML techniques and how to apply them to your own datasets using the R programming language and its powerful ecosystem of tools. This book will get you started!  Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the book  Machine Learning with R, the tidyverse, and mlr gets you started in machine learning using R Studio and the awesome mlr machine learning package. This practical guide simplifies theory and avoids needlessly complicated statistics or math. All core ML techniques are clearly explained through graphics and easy-to-grasp examples. In each engaging chapter, you’ll put a new algorithm into action to solve a quirky predictive analysis problem, including Titanic survival odds, spam email filtering, and poisoned wine investigation. What's inside  Using the tidyverse packages to process and plot your data Techniques for supervised and unsupervised learning Classification, regression, dimension reduction, and clustering algorithms Statistics primer to fill gaps in your knowledge About the reader  For newcomers to machine learning with basic skills in R. About the author  Hefin I. Rhys is a senior laboratory research scientist at the Francis Crick Institute. He runs his own YouTube channel of screencast tutorials for R and RStudio.  Table of contents: PART 1 - INTRODUCTION 1.Introduction to machine learning 2. Tidying, manipulating, and plotting data with the tidyverse PART 2 - CLASSIFICATION 3. Classifying based on similarities with k-nearest neighbors 4. Classifying based on odds with logistic regression 5. Classifying by maximizing separation with discriminant analysis 6. Classifying with naive Bayes and support vector machines 7. Classifying with decision trees 8. Improving decision trees with random forests and boosting PART 3 - REGRESSION 9. Linear regression 10. Nonlinear regression with generalized additive models 11. Preventing overfitting with ridge regression, LASSO, and elastic net 12. Regression with kNN, random forest, and XGBoost PART 4 - DIMENSION REDUCTION 13. Maximizing variance with principal component analysis 14. Maximizing similarity with t-SNE and UMAP 15. Self-organizing maps and locally linear embedding PART 5 - CLUSTERING 16. Clustering by finding centers with k-means 17. Hierarchical clustering 18. Clustering based on density: DBSCAN and OPTICS 19. Clustering based on distributions with mixture modeling 20. Final notes and further reading},
	language = {English},
	publisher = {Manning},
	author = {Rhys, Hefin I.},
	month = mar,
	year = {2020},
}

@article{project_data_2024,
	title = {Data from {ManyDogs} 1},
	volume = {12},
	issn = {2050-9863},
	url = {https://openpsychologydata.metajnl.com/articles/10.5334/jopd.109},
	doi = {10.5334/jopd.109},
	abstract = {The Journal of Open Psychology Data (JOPD) publishes peer-reviewed data papers describing psychology datasets with high reuse potential. Data papers may describe datasets from unpublished work or from papers published previously in a traditional journal. We welcome submissions from all areas of psychology including replication research, qualitative research and meta-research. We hope to reward authors for sharing datasets according to FAIR principles, providing structure for the data and papers to be citable, and for reuse to be tracked.},
	language = {en-US},
	number = {1},
	urldate = {2024-10-02},
	journal = {Journal of Open Psychology Data},
	author = {Project, ManyDogs and Espinosa, Julia and Hare, Elizabeth and Alberghina, Daniela and Valverde, Bryan Mitchel Perez and Stevens, Jeffrey R.},
	month = aug,
	year = {2024},
	file = {Full Text PDF:C\:\\Users\\lmwol\\Zotero\\storage\\2ZMSAMYI\\Project et al. - 2024 - Data from ManyDogs 1.pdf:application/pdf},
}
